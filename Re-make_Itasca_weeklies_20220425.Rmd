---
title: "Re-make_Itasca_weeklies"
author: "Sara DeLaurentis"
date: "4/25/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(stringr)
library(tidyverse)
library(lubridate)
library(ggplot2)

library(zoo)
```

## R Markdown


```{r }
data <- read.csv("ALL.csv")

data$date.time <- data$date.time %>% as.POSIXlt(tz = "") #set date/time class to POSIXlt for greater ease in parsing date elements.
head(data$date.time)

# -- subset by date, add week-counting columns, calculate weekly means --

START <- as.POSIXlt("2020-10-01 00:00:00", tz = "")
#BREAK <- as.POSIXlt("2020-08-25", tz = "")
#RESUME <- as.POSIXlt("2020-09-30", tz = "")
END <- as.POSIXlt("2021-10-01 00:00:00", tz = "")

data <- data %>% 
  subset.data.frame(date.time >= START & date.time <= END) %>% #subset the whole df                         
  filter(!is.na(value))  # Apply filter & !is.na

week.START <- as.POSIXlt("2020-10-01 00:00:00", tz = "")
wday.no <- as.POSIXlt(week.START)$wday #store weekday integer
data$week.begin <- floor_date(as.POSIXlt(data$date.time), unit = "weeks", week_start = wday.no) #create week.begin column
data$week.no <- (1 + difftime(data$week.begin, week.START, units = "weeks")) %>% 
  round()
#data[1:25,]

# WEEKLY.MEANS.DF STARTING AT "data"
weekly.means.df <- data %>%
  group_by(site, rep, position) %>% 
  mutate(length = length(date.time)) %>% 
  filter(length > 500)


# CHOOSE A PATH: Weekly mean with set weeks, or rollmean:

#Set weeks
weekly.means.df <- weekly.means.df %>%
  group_by(site, rep, position, week.no) %>% 
  summarise(site = site, 
            rep = rep, 
            position = position, 
            week.no = week.no, 
            week.begin = week.begin, 
            meantemp = round(mean(value), 2))

#Rolling mean
weekly.means.df <- data %>%
  group_by(site, rep, position) %>% 
  mutate(weekly.roll = rollmean(value, 7))

weekly.means.df <- weekly.means.df %>%
  group_by(site, rep, position) %>% 
  summarise(site = site, 
            rep = rep, 
            position = position, 
            meantemp = round(mean(value), 2),
            weekly.roll = weekly.roll)


#how many values are in each group? Use this column to weed out sensors with only a few cells of data.

weekly.means.df <- weekly.means.df %>% 
  subset.data.frame(length > 20) #only select rows where the length column value is greater than 500.
#weekly.means.df$length = NULL # delete length column 

view(weekly.means.df)



```


```{r }
 #SKIP this group for rolling mean:
weekly.sums.df <- weekly.means.df %>% 
  group_by(site, rep, position) %>% 
  summarise(annual.mean = round(mean(meantemp), 2), 
            min = min(meantemp),
            min_temp_time = date(week.begin[which.min(x = meantemp)]),
            max = max(meantemp),
            max_temp_time = date(week.begin[which.max(x = meantemp)]))


#For rolling weekly mean:

weekly.sums.df <- weekly.means.df %>% 
  group_by(site, rep, position) %>% 
  summarise(annual.mean = round(mean(meantemp), 2), 
            min = min(meantemp),
            min_temp_time = date(week.begin[which.min(x = meantemp)]),
            max = max(meantemp),
            max_temp_time = date(week.begin[which.max(x = meantemp)]))

#print(weekly.sums.df)
view(weekly.sums.df)

write_csv(weekly.sums.df, "Weekly_summs_roll_OCT_v1.csv")

```
## might not need the stuff below here

```{r }

data <- mutate(date.time = mdy_hms(date.time)) %>% 
  separate('date.time',
           into = c('longdate', 'time'),
           sep = ' ') %>% 
  separate('longdate',
                into = c('year', 'month', 'day'),
                sep = '-',
                remove = FALSE) %>% 
  group_by(year, month, week) %>% 
  summarise(meantemp = mean(value)) 


```


